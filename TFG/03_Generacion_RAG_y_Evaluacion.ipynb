{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52b80317",
   "metadata": {},
   "source": [
    "# 03. Despliegue del Modelo e Integración RAG (Fase de Validación)\n",
    "\n",
    "## Objetivos de este Notebook\n",
    "1.  **Carga del SLM:** Desplegar el modelo **Microsoft Phi-3-mini-4k-instruct** en la GPU (RTX 4090).\n",
    "2.  **Conexión Distribuida:** Establecer comunicación con Elasticsearch (alojado en CPU/Valencia) mediante túnel SSH.\n",
    "3.  **Pipeline RAG:** Implementar la función de búsqueda y generación con configuración estricta (**Top-k=1**, **Match Perfecto**) para mitigar alucinaciones.\n",
    "4.  **Validación Técnica:** Realizar pruebas manuales de cordura (Sanity Checks) para asegurar que el sistema recupera noticias reales y admite ignorancia cuando no hay datos.\n",
    "\n",
    "## Requisitos Previos\n",
    "* Túnel SSH activo en terminal: `ssh -L 9250:localhost:9250 javierruiz@valencia...`\n",
    "* Elasticsearch corriendo en el servidor remoto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2b6a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javierruiz/miniconda3/envs/environment/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hardware detectado: NVIDIA GeForce RTX 4090\n",
      "Cargando modelo: microsoft/Phi-3-mini-4k-instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading weights: 100%|██████████| 195/195 [00:01<00:00, 125.49it/s, Materializing param=model.norm.weight]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ¡Modelo SLM cargado y listo para inferencia!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# 1. Configuración de Hardware\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Hardware detectado: {torch.cuda.get_device_name(0) if device == 'cuda' else 'CPU'}\")\n",
    "\n",
    "# 2. Selección de Modelo (Empezamos con un SLM para la prueba rápida)\n",
    "MODEL_ID = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "print(f\"Cargando modelo: {MODEL_ID}...\")\n",
    "\n",
    "# 3. Carga del Tokenizer y el Modelo \n",
    "# Importante: Ponemos trust_remote_code=False para usar la versión estable instalada\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=False)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    device_map=\"auto\",             # Distribuye automáticamente en la GPU\n",
    "    torch_dtype=torch.float16    # Usamos precisión media para ahorrar VRAM y ganar velocidad\n",
    ")\n",
    "\n",
    "# 4. Crear Pipeline de Generación\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "print(\"\\n ¡Modelo SLM cargado y listo para inferencia!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c73c2c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'temperature', 'do_sample', 'max_new_tokens'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Generando respuesta...\n",
      "\n",
      "==================================================\n",
      " La inflación económica es un fenómeno que se refiere a la tasa a la que el nivel general de precios de bienes y servicios está aumentando, y, por ende, el poder adquisitivo está disminuyendo. En otras palabras, a medida que la inflación aumenta, cada unidad de moneda compra menos bienes y servicios. La inflación puede ser causada por diversos factores, incluyendo un aumento en la oferta de dinero, un aumento en los costos de producción, o una disminución en la demanda de bienes y servicios. Las autoridades monetarias, como el Banco\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# 5. Prueba de Inferencia (Sin RAG todavía)\n",
    "# Vamos a ver si el \"cerebro\" funciona por sí solo.\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"¿Podrías explicarme brevemente qué es la inflación económica?\"},\n",
    "]\n",
    "\n",
    "# Configuración de generación\n",
    "generation_args = {\n",
    "    \"max_new_tokens\": 150,     # Que no escriba una novela, solo un párrafo\n",
    "    \"return_full_text\": False, # Que no repita la pregunta\n",
    "    \"temperature\": 0.1,        # Creatividad baja (queremos datos, no poesía)\n",
    "    \"do_sample\": True,\n",
    "}\n",
    "\n",
    "print(\" Generando respuesta...\")\n",
    "output = pipe(messages, **generation_args)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(output[0]['generated_text'])\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b788314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING EXITOSO\n",
      " Conectado a: valencia\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# Ahora que las versiones coinciden, la configuración es estándar y sencilla\n",
    "es = Elasticsearch(\"http://127.0.0.1:9250\")\n",
    "\n",
    "try:\n",
    "    if es.ping():\n",
    "        print(\"PING EXITOSO\")\n",
    "        print(f\" Conectado a: {es.info()['name']}\")\n",
    "    else:\n",
    "        print(\"❌ El servidor no responde. ¿Está el túnel abierto?\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac82dc29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Sistema RAG (k=1) reconfigurado para devolver datos separados.\n"
     ]
    }
   ],
   "source": [
    "def ask_rag(query, top_k=1): \n",
    "    \"\"\"\n",
    "    Función RAG para TFG: Recupera 1 noticia y genera respuesta basada estrictamente en ella.\n",
    "    Retorna un diccionario con los datos separados.\n",
    "    \"\"\"\n",
    "    # --- A. BÚSQUEDA ---\n",
    "    search_payload = {\n",
    "        \"size\": top_k,\n",
    "        \"query\": {\n",
    "            \"multi_match\": {\n",
    "                \"query\": query,\n",
    "                \"fields\": [\"title^3\", \"body\"],\n",
    "                \"fuzziness\": 0\n",
    "            }\n",
    "        },\n",
    "        \"_source\": [\"title\", \"body\", \"date\", \"source\"]\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = es.search(index=\"noticias_tfg\", body=search_payload)\n",
    "        hits = response['hits']['hits']\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Error en Elasticsearch: {e}\"}\n",
    "    \n",
    "    if not hits:\n",
    "        return {\"error\": \" NO ENCONTRADO: No hay ninguna noticia que coincida exactamente con la búsqueda.\"}\n",
    "\n",
    "    # --- B. EXTRACCIÓN ---\n",
    "    doc = hits[0]['_source']\n",
    "    contexto_unico = f\"\"\"\n",
    "    TITULO: {doc.get('title')}\n",
    "    FECHA: {doc.get('date', 'Desconocida')}\n",
    "    FUENTE: {doc.get('source', 'Desconocida')}\n",
    "    CONTENIDO: {doc.get('body')}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- C. PROMPT ---\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"\n",
    "        Eres un sistema de verificación de datos (Fact-Checking). \n",
    "        Tu objetivo es responder a la pregunta usando ÚNICAMENTE el texto que te proporciono abajo.\n",
    "\n",
    "        REGLAS CRÍTICAS:\n",
    "        1. Si la respuesta no aparece en el texto, responde exactamente: \"No tengo información suficiente en mis archivos\".\n",
    "        2. No utilices conocimiento externo.\n",
    "        3. No menciones otras noticias que no sean la proporcionada.\n",
    "\n",
    "        ### TEXTO DE REFERENCIA:\n",
    "        {contexto_unico}\n",
    "        \n",
    "        ### PREGUNTA:\n",
    "        {query}\n",
    "        \"\"\"}\n",
    "    ]\n",
    "\n",
    "    # --- D. GENERACIÓN ---\n",
    "    outputs = pipe(\n",
    "        messages,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=False,\n",
    "        temperature=0.0, \n",
    "    )\n",
    "    \n",
    "    # --- E. RETORNO ESTRUCTURADO  ---\n",
    "    # Extraemos solo el texto del último mensaje \n",
    "    respuesta_limpia = outputs[0]['generated_text'][-1]['content']\n",
    "    \n",
    "    return {\n",
    "        \"titulo\": doc.get('title'),\n",
    "        \"contenido\": doc.get('body'),\n",
    "        \"fecha\": doc.get('date'),\n",
    "        \"fuente\": doc.get('source'),\n",
    "        \"respuesta_rag\": respuesta_limpia # Aquí va solo el texto que querías\n",
    "    }\n",
    "\n",
    "print(\"✅ Sistema RAG (k=1) reconfigurado para devolver datos separados.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b54e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Passing `generation_config` together with generation-related arguments=({'max_new_tokens'}) is deprecated and will be removed in future versions. Please pass either a `generation_config` object OR all generation parameters explicitly, but not both.\n",
      "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PREGUNTA: ¿Qué aranceles puso Trump a China?\n",
      "\n",
      "--- RESPUESTA SLM (SIN RAG) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " El presidente Donald Trump impuso aranceles a China en 2018 como parte de una política comercial destinada a reducir el déficit comercial estadounidense y proteger las industrias estadounidenses de la competencia china. Los aranceles, conocidos como \"tasa de penalización\", aumentaron progresivamente, afectando una amplia gama de productos. Entre ellos figuraban equipos de computadora, teléfonos móviles, automóviles, paneles solares, y bienes electrónicos, entre otros. Este enfoque comercial empezó a tensar las relaciones económicas entre Estados Unidos y China, lo\n",
      "\n",
      "\n",
      "--- RESPUESTA SISTEMA RAG ---\n",
      "NOTICIA: Aranceles de Trump a China alcanzan el 145%\n",
      "TEXTO: La Casa Blanca precisó que el aumento del 125% de aranceles a China se suma al 20% vigente desde principios de marzo. (...)\n",
      "FUENTE: Excélsior\n",
      "RESPUESTA:  El presidente Trump puso aranceles a China que suman un 125% al 20% vigente desde principios de marzo.\n"
     ]
    }
   ],
   "source": [
    "pregunta_tfg = \"¿Qué aranceles puso Trump a China?\"\n",
    "\n",
    "print(f\" PREGUNTA: {pregunta_tfg}\\n\")\n",
    "\n",
    "# 1. Prueba SIN RAG \n",
    "print(\"--- RESPUESTA SLM (SIN RAG) ---\")\n",
    "res_base = pipe([{\"role\": \"user\", \"content\": pregunta_tfg}], max_new_tokens=150)\n",
    "print(res_base[0]['generated_text'][-1]['content']) # Solo el texto generado, sin repetir la pregunta\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Ejecutamos el RAG\n",
    "datos = ask_rag(pregunta_tfg)\n",
    "print(\"--- RESPUESTA SISTEMA RAG ---\")\n",
    "# 1. Imprimimos Título\n",
    "print(f\"NOTICIA: {datos['titulo']}\")\n",
    "\n",
    "# 2. Imprimimos Contenido (Recortado un poco para no llenar pantalla)\n",
    "print(f\"TEXTO: {datos['contenido'][:300]} (...)\")\n",
    "print(\"FUENTE: \" + datos['fuente'])\n",
    "# 3. Imprimimos SOLO la respuesta limpia del RAG\n",
    "print(f\"RESPUESTA: {datos['respuesta_rag']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e068820",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=150) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PREGUNTA: ¿Cuál dijo Pedro Sánchez que era su principal prioridad en la clausura del 41 Congreso Federal del PSOE?\n",
      "\n",
      "--- RESPUESTA SLM (SIN RAG) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Both `max_new_tokens` (=256) and `max_length`(=20) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Durante la clausura del 41 Congreso Federal del PSOE, el entonces secretario general Pedro Sánchez, en un discurso público, enfatizó la necesidad de trabajar por la transición exitosa hacia la convocatoria de las elecciones generales de 2023, que eran una de sus principales prioridades. Dijo que era fundamental para el partido y para la nación avanzar hacia un proceso democrático que permitiera al pueblo español elegir a sus representantes.\n",
      "\n",
      "\n",
      "--- RESPUESTA SISTEMA RAG ---\n",
      "NOTICIA: Todos los señalados por Pedro Sánchez en el Congreso Federal del PSOE\n",
      "TEXTO: Pedro Sánchez aseguró en la clausura el domingo en Sevilla del 41 Congreso Federal del PSOE que su «principal prioridad» sería revalidar su propio mandato en 2027 y, al mismo tiempo, recuperar el poder territorial que perdieron los socialistas frente al PP ... en 2023.Andalucía Juan Espadas De candidato contra Díaz a discutidoEl líder del PSOE andaluz ha pasado en dos años de ser el elegido por Ferraz para derrocar a Susana Díaz en unas primarias a caer en desgracia. Por si quedaba alguna duda, Sánchez la despejó el domingo al evitar ratificarle como candidato, un desprecio aún mayor al producirse cuando presidía el congreso y en la ciudad de la que fue alcalde. Nada más terminar el cónclave, Espadas confirmó que irá a unas primarias y retó a los críticos a presentarse. Noticia Relacionada estandar Si Sánchez apuesta por confrontar para recuperar el poder territorial Mariano Alonso El presidente del Gobierno es reelegido por cuarta vez al frente de su partido con una Ejecutiva continuista. La frialdad del líder del partido con el anfitrión, Juan Espadas, agita aún más a los socialistas andalucesCantabria Pablo Zuloaga El vicepresidente con Revilla o la alternativaEl actual líder del partido en Cantabria, que fue vicepresidente en la coalición con el regionalista Miguel Ángel Revilla, no tiene segura su continuidad. En el camino le ha salido un rival de envergadura, el diputado por esa circunscripción en el Congreso, Pedro Casares, quien publicamente no ha descartado presentarse. Castilla y León Luis Tudanca El sanchista rebeldeEs muy difícil, casi imposible, encontrar un dirigente en el PSOE que haya sido tan defensor de Pedro Sánchez y tan leal siempre, incluso en las peores circunstancias, al secretario general del partido. Pese a ello, Ferraz está decidido a sustituirle en una comunidad donde las elecciones tocan en 2026 pero incluso podrían volver a adelantarse. Ya en octubre le impideron celebrar primarias antes del Congreso Federal y estalló entonces denunciando prácticas tóxicas contra su federación del secretario de Organización, Santos Cerdán. Está dispuesto a dar la batalla, y podría tener como rival al alcalde de Soria, Carlos Martínez. Madrid Óscar López De segoviano a madrileñoEl ministro de Transformación Digital presentará el jueves su candidatura para liderar el PSM. Su jefa de gabinete, Pilar Sánchez Acera, fue quien en marzo tuvo la conversación con el dimitido Juan Lobato que éste llevó al notario, como desveló en exclusiva ABC.Óscar López presume ahora de su natalidad madrileña, aunque entre 2008 y 2012 lideró al PSOE de Castilla y León en virtud a sus origenes segovianos. Viejo amigo de Sánchez, cuando a ambos los apadrinaba José Blanco, se distanció del presidente hasta volver a su lado en 2021 como sustituto de Iván Redondo en Moncloa. Aragón Pilar Alegría La portavoz aguardaLa jubilación política del expresidente Javier Lambán obliga a encontrar un sustituto, en una de las federaciones que ha sido más crítica con Sánchez los últimos años. La señalada es la portavoz del Gobierno, Pilar Alegría, quien en 2019 fue candidata a la alcaldía de Zaragoza. De momento aguarda a dar el paso, en un clima de ruptura total con Lambán, quien quejado de un cáncer se distancia cada vez más del aparato y algunos de sus postulados.\n",
      "FUENTE: ABC.es\n",
      "RESPUESTA:  Su principal prioridad sería revalidar su propio mandato en 2027 y, al mismo tiempo, recuperar el poder territorial que perdieron los socialistas frente al PP... en 2023.\n"
     ]
    }
   ],
   "source": [
    "pregunta_tfg = \"¿Cuál dijo Pedro Sánchez que era su principal prioridad en la clausura del 41 Congreso Federal del PSOE?\"\n",
    "\n",
    "print(f\" PREGUNTA: {pregunta_tfg}\\n\")\n",
    "\n",
    "# 1. Prueba SIN RAG \n",
    "print(\"--- RESPUESTA SLM (SIN RAG) ---\")\n",
    "res_base = pipe([{\"role\": \"user\", \"content\": pregunta_tfg}], max_new_tokens=150)\n",
    "print(res_base[0]['generated_text'][-1]['content']) # Solo el texto generado, sin repetir la pregunta\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Ejecutamos el RAG\n",
    "datos = ask_rag(pregunta_tfg)\n",
    "print(\"--- RESPUESTA SISTEMA RAG ---\")\n",
    "# 1. Imprimimos Título\n",
    "print(f\"NOTICIA: {datos['titulo']}\")\n",
    "\n",
    "# 2. Imprimimos Contenido (Recortado un poco para no llenar pantalla)\n",
    "print(f\"TEXTO: {datos['contenido']}\")\n",
    "print(\"FUENTE: \" + datos['fuente'])\n",
    "# 3. Imprimimos SOLO la respuesta limpia del RAG\n",
    "print(f\"RESPUESTA: {datos['respuesta_rag']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "environment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
